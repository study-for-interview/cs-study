# 동기/비동기와 블로킹/논블로킹

동기/비동기는 작업을 수행하는 주체가 두 개 이상이어야 합니다. 

이 때 작업의 시간(시작, 종료 등)을 서로 맞춘다면 이를 **동기**라고 부르고, 서로 작업의 시간이 관계없다면 이를 **비동기**라고 부릅니다. 

반면 블로킹/논블로킹은 작업의 대상이 2개 이상이어야 합니다. 

두 개념이 서로 바라보는 관점이 다르기 때문에 동기/블로킹, 동기/논블로킹, 비동기/블로킹, 비동기/논블로킹의 다양한 조합이 가능합니다.

 ## 동기
 동기 작업이란 작업을 수행하는 두 개 이상의 주체가 서로 동시에 수행하거나, 동시에 끝나거나, 끝나는 동시에 시작할 때를 의미합니다. 
 
 시작과 종료를 동시에 하거나, 하나의 작업이 끝나는 동시에 다른 주체가 작업을 시작하면 이는 동기 작업이라고 볼 수 있습니다.

## 비동기
 비동기 작업은 두 주체가 서로의 시작, 종료시간과는 관계 없이 별도의 수행 시작/종료시간을 가지고 있을 때를 뜻합니다. 
 
 서로 다른 주체가 하는 작업이 자신의 작업 시작, 종료시간과는 관계가 없을 때 비동기라고 부를 수 있습니다.

 ![image](https://blog.kakaocdn.net/dn/dxv5bm/btqDZX6x7aF/qoGwd60NkaxZFPsRSFrpK1/img.png)

 ## 블로킹/논블로킹

 블로킹과 논블로킹은 다른 작업을 수행하는 주체를 어떻게 상대하는지가 중요합니다. 
 
 자신의 작업을 하다가 다른 작업 주체가 하는 작업의 시작부터 끝까지 기다렸다가 다시 자신의 작업을 시작한다면 이는 블로킹이고, 다른 주체의 작업과 관계없이 자신의 작업을 계속한다면 이를 논블로킹이라고 할 수 있습니다.

### 블로킹
 스레드 A가 어떤 작업을 하는 다른 대상을 호출하고, 그 대상이 가져온 결과물을 받아 다시 작업을 재개하고 있습니다. 예를 들자면 Java에서 JDBC를 사용하여 DB에 질의를 날리고 결과를 받아오는 작업을 블로킹 작업이라고 부를 수 있습니다. 
 
 ### 논블로킹
 이와 반대로 다른 주체에게 작업을 요청하고 그 결과를 받을 때까지 기다리지 않으며 자신의 작업을 한다면 이를 논블로킹이라고 할 수 있습니다.

 ![image](https://blog.kakaocdn.net/dn/KAhB9/btqDZYxAX5n/m287hwVpNKPgnnjaItsU91/img.png)


## 동기/비동기와 블로킹/논블로킹의 조합
![image](https://blog.kakaocdn.net/dn/cBveNG/btqDY12Hdd0/j3UtHIiNTNgy7fzVoDELl1/img.png)

## 동기 - 블로킹
동기이며 블로킹인 작업은 어떤 작업이 있을까요? 

동기의 조건인 '두 개 이상의 작업의 시작시간, 종료시간이 같거나 시작과 동시에 종료할 것', 그리고 블로킹의 조건인 '다른 작업을 하는 동안 자신의 작업을 일시정지할 것' 을 만족하는 작업의 예는 아래와 같습니다.

- JDBC를 이용해 DB에 쿼리 질의를 날린다
- 메서드에서 다른 메서드를 호출하여 결과값을 즉시 받아온다

![동기-블로킹](https://blog.kakaocdn.net/dn/vFNms/btqD0ivZl0w/3yEK5Ai8nd4s2el3TjaID1/img.png)


## 비동기 - 블로킹
비동기의 조건인 '다른 작업과 시작, 종료 시간을 맞추지 말 것'과 블로킹의 조건인 '다른 작업의 주체가 작업하는동안 기다릴 것'을 만족해야 합니다. 

비동기, 블로킹 조합은 결국 다른 작업이 끝날 때를 기다려야 하기 때문에 동기, 블로킹과 비슷한 작업 효율이 나옵니다. 

즉 그리 좋은 효율이 나오지 않습니다. 개발자가 유도해서 이 상황을 만드는 것보다 비동기, 논블로킹 작업을 실행하였지만 자기도 모르게 블로킹 작업을 실행했을 때 이러한 결과가 나옵니다.

![image](https://blog.kakaocdn.net/dn/btDMtb/btqD2cuJUSZ/OJl5C289kZ7kQ6pDYDfkLK/img.png)

## 동기 - 논블로킹

동기의 조건인 '두 개 이상의 작업의 시작시간, 종료시간이 같거나 시작과 동시에 종료할 것', 논블로킹의 조건인 '다른 작업의 주체가 작업하는동안 기다리지 말 것' 을 만족하는 동기, 논블로킹 조합도 비동기, 블로킹 조합처럼 작업 효율이 좋지 않은 편입니다.

 논블로킹으로 자신의 작업을 계속하고 있지만 다른 작업과의 동기를 위해 계속해서 다른 작업이 끝났는지 조회합니다.

 ![동기 - 논블로킹](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FLCjtN%2FbtqD2v8GDcL%2F7fxHakhJSPIUnWhxzBk3qk%2Fimg.png)

 
## 비동기 - 논블로킹

 '다른 작업과 시작, 종료 시간을 맞추지 말 것', '다른 작업의 주체가 작업하는동안 기다리지 말 것' 을 만족하는 비동기, 논블로킹 조합은 자원이 충분하다면 효율이 좋은 조합입니다. 
 
 자신의 작업이 멈추지도 않고, 다른 주체가 하는 작업의 결과가 나왔을 때 콜백을 설정하기도 합니다. 다른 주체에게 작업을 맡겨놓고 자신이 하던 일을 계속할 수 있기 때문에 해야 할 작업이 대규모이고, 동기가 필요하지 않을 때 효과적입니다.

- 대규모 사용자에게 푸시메세지 전송
- 다양한 외부 API를 한번에 호출할 때

![비동기 - 논블로킹 image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FlTvwR%2FbtqD2H15VX7%2F50jOhlnxu5gbmfSSSO620k%2Fimg.png)



# 프로세스 동기화

현대 컴퓨터의 메모리에는 여러 프로세스가 존재하는데, 이러한 프로세스들이 하나의 공유 메모리나 또 다른 프로세스에 접근할 때는 매우 신중해야 한다. 

이처럼 한 프로세스가 다른 프로세스에게 영향을 받거나 주는 프로세스를 **Cooperating process** 라고 한다.

반대로 아무런 영향을 미치지 않는 독립적인 프로세스는 Independent process이다.

현대 컴퓨터 환경에는 cooperating process가 훨씬 많이 존재하고, 이들은 서로 영향을 미치기 때문에 데이터나 흐름에 대한 동기화가 매우 중요하다. 

프로세스 사이에 동기화를 하는 것을 **프로세스 동기화(Process Synchronization)** 라고 한다.

대표적인 예 : 기차표 좌석 예매

프로세스 동기화는 여러 프로세스가 **공유하는 자원의 일관성** 을 유지하는 것이다.

 가령 여러 프로세스가 동시에 하나의 공유된 자원에 접근하려고 할 때 이 프로세스들의 순서를 정하여 데이터의 일관성을 유지시켜주어야 한다.

[은행 계좌 문제 예시](https://velog.io/@codemcd/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9COS-8.-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%EB%8F%99%EA%B8%B0%ED%99%94-1)

동기화가 제대로 이루어지지 않으면 은행 계좌 문제처럼 정상적인 결과값이 나오지 않을 수 있다.

이러한 문제가 발생하는 원인은 **공통변수(common variable)에 대한 동시 업데이트(concurrent update))** 때문이다.

해당 예시에서는 balance가 공통 변수로 사용되었고 여러 스레드가 동시에 접근할 수 있는 상황에서 제대로 된 동기화 처리가 되지 않아서 비정상적인 결과값이 나왔다.

이를 해결하는 방법은 공통변수에 접근하는 스레드는 하나만 존재하도록 관리해야 한다.
이러한 공통변수 구역을 **임계구역(Critical section)** 이라고 한다.

- Critical Section

임계구역은 여러 개의 쓰레드가 수행되는 시스템에서 각 쓰레드들이 **공유하는 데이터(변수, 테이블, 파일 등)를 변경하는 코드 영역** 을 말한다. 이는 동기화에서 중요한 문제 중 하나이다.

```java
void deposit(int amount) {
  balance = balance + amount;
}
void withdraw(int amount) {
  balance = balance - amount;
}
```
위 은행계좌 문제에서의 임계구역이다.


## 해결책
임계구역을 해결하기 위해서는 3가지 조건이 만족해야한다.

- **Mutual exclusion(상호배타)** - 오직 한 쓰레드만이 진입 가능하다. 한 쓰레드가 임계구역에서 수행 중인 상태에서는 다른 쓰레드는 절대 이 구역에 접근할 수 없다.

    - 단일 프로세서 시스템에서 상호배제를 구현하는 간단한 방법은 인터럽트를 억제해서 공유데이터 손상을 막는 것이다. 일종의 Locking 메커니즘이라 할 수 있다. lock을 가진 쓰레드만이 임계구역에 접근할 수 있는것이다. 임계구역에서 작업이 끝난 쓰레드는 Unlock하여 lock을 반환한다. 

![lock](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile21.uf.tistory.com%2Fimage%2F99DA90395AE57DDF166735)


- **Progress(진행)** - Critical Section 에서 실행중인 프로세스가 없고, 별도의 동작이 없는 프로세스들만 Critical Section 진입 후보로서 참여될 수 있다.

- **Bounded waiting(유한대기)** - 같은 프로세스가 임계구역을 독점하지 못하게 한다. 다른 프로세스의 starvaion을 막기 위해 한번 하나의 프로세스가 critical section에 들어가려고 요청한 이후부터는 한정된 대기 횟수 안에 해당 프로세스가 critical section에 들어가야한다.


### Lock

```
 하드웨어 기반 해결책으로써, 동시에 공유 자원에 접근하는 것을 막기 위해 critical section에 진입하는 프로세스는 lock을 획득하고 critical section에 진입하는 프로세스는 lock을 획득하고 critical section을 빠져나올 때, lock을 방출함으로써 동시에 접근이 되지 않도록 한다.
 critical section으로의 진입 가능성 확인과 동시에 진입 거부를 원자적으로 한번에 처리한다.
```

단점
- 락이 걸려있는 경우 인터럽트가 되지 않기 때문에 다중 처리기 환경에서는 
    효율성 측면에서 적용할 수 없다.


### Semaphores
- 소프트웨어상에서 Critical Section 문제를 해결하기 위한 동기화 도구

세마포어 S는 정수값을 가지는 변수이며 다음과 같은 P와 V라는 명령어에 의해서만 접근할 수 있다. (P와 V는 try와 increment를 뜻하는 네델란드어에서 따왔다.)

P는 임계구역에 들어가기 전에 수행되고(try) , V는 임계구역에서 나올 때 수행된다(increase). 

이 때 변수값을 수정하는 연산은 모두 '원자성'을 만족해야 한다. 다시 말해, 한 프로세스나 쓰레드에서 S값을 변경하는 동안에는 다른 프로세스나 쓰레드가 동시에 접근해서 변경할 수 없다. 

값이 0보다 크면 접근을 허용하되 1을 감소하고, 값이 0이면 접근을 block시킨다.  반대로 작업이 끝나고 프로세스나 쓰레드가 나갈때는 값을 1로 증가시켜 다른 프로세스나 스레드가 접근할 수 있도록 한다. 여기서 접근되는 자원은 임계구역이므로 시스템 퍼포먼스에 많은 영향을 끼친다.


최초 제시된 방법은 Busy-Waiting(바쁜대기,대기중인 쓰레드가 여전히 활성상태이지만 아무 작업도 하지 않는 상태)를 활용하는 방법이다.
```
 P(S) {
     while S <=0; // 아무것도 하지 않음 (반복문)
     S--;
 }

 V(S) {
     S++;
 }
```
이 방법은 임계구역에 진입하기 전 까지 빈 반복문을 계속 수행하므로 단일 처리기 다중 프로세스 환경에서는 효율이 떨어진다. 또한 대기중인 프로세스 중 어느것을 먼저 임계구역에 진입시킬지 결정할 수 없다.

첫번째 방법의 단점을 보완한 방법으로써 '재움 큐'를 활용한 방법이다.

```
 P(S) {
     S--;
     if S < 0
         // 이 프로세스를 재움 큐에 추가 (잠 듦)
 }

 V(S) {
     S++;
     if S <= 0
         // 재움 큐로부터 프로세스를 제거 (깨어남)
 }
```

- 종류 : OS 는 Counting/Binary 세마포를 구분한다
- 카운팅 세마포

  - 가용한 개수를 가진 자원 에 대한 접근 제어용으로 사용되며, 세마포는 그 가용한 자원의 개수 로 초기화 된다. 자원을 사용하면 세마포가 감소, 방출하면 세마포가 증가 한다.

- 이진 세마포

  - MUTEX 라고도 부르며, 상호배제의 (Mutual Exclusion)의 머릿글자를 따서 만들어졌다. 이름 그대로 0 과 1 사이의 값만 가능하며, 다중 프로세스들 사이의 Critical Section 문제를 해결하기 위해 사용한다.


## 뮤텍스와 세마포어의 차이

우리(프로세스)가 방(자원)에 들어가려고 할 때, 뮤텍스는 방에 들어가기 위한 열쇠의 개수이며, 세마포어는 빈 방의 열쇠의 개수이다.

즉 뮤텍스는 한 사람이 빈 방에 대한 열쇠를 가지고 있어서 방에 들어간다면, 그 사람이 나와야만 다른 사람이 열쇠를 건네받아 방을 들어갈 수 있다.

반면 세마포어는 방이 네개면 열쇠도 네개일 것이고 한 사람이 들어갈 때마다 들어갈 수 있는 방은 하나씩 줄어들어 0개가 되면 빈 방이 나올때 까지 대기해야 하는 상황이다. 아무나 먼저 나와야만 방과 열쇠를 한개씩 얻어서 들어갈 수 있다.


- 세마포어는 자원의 상태를 나타내는 일종의 '변수'로써 소유 개념이 아니지만, 뮤텍스는 자원을 점유한 프로세스나 쓰레드가 잠시 소유하였다가 작업이 끝나면 반환하는 개념이다.

- 가장 큰 차이점은 뮤텍스가 동기화 대상이 자원의 하나라면, 세마포어는 하나 이상일 때 사용된다.

[참고: https://dduddublog.tistory.com/25](https://dduddublog.tistory.com/25)



## Busy-Wait vs Block/wakeup

 - Block/wakeup overhead vs Critical section 길이
     - Critical section의 길이가 긴 경우 Block/wakeup이 적당
    - Critical section의 길이가 매우 짧은 경우 Block/Wakeup 오버헤드가 busy-wait 오버헤드보다 더 커질 수 있음
    - 일반적으로는 Block/wakeup 방식이 더 좋음

## Deadlock(교착상태)
- 둘 이상의 프로세스가 서로 상대방에 의해 충족될 수 있는 event를 무한히 기다리는 현상

![image](https://user-images.githubusercontent.com/47075043/149684339-9acb63b8-e6de-4fcc-af13-728ecacf4318.png)


## 모니터

- 세마포어의 문제점
    - 코딩하기 어렵다.
    - 정확성(correctness)의 입증이 어렵다.
    - 자발적 협력(voluntary cooperation)이 필요하다.
    - 한번의 실수가 모든 시스템에 치명적 영향을 끼친다.

예 : ![image](https://user-images.githubusercontent.com/47075043/149684583-c60883b6-b93a-4f42-890d-425ad3770844.png)

- 동시 수행중인 프로세스 사이에서 abstract data type의 안전한 공유를 보장하기 위한 high-level synchronization construct

- 공유데이터를 접근하기 위해서는 monitor라고 정의한 프로시져를 통해서만 공유데이터를 접근할 수 있도록 해놓고 monitor는 원천적으로 동시에 접근할 수 없도록 한다.

세마포어와의 차이점
- lock을 걸 필요가 없다.

프로세스가 모니터 안에서 기다릴 수 있도록 하기 위해 Condition variable을 사용한다.

## 메모리 관리 전략
- 메모리 관리 배경
    - 여러 프로세스가 한정된 자원을 사용하기 떄문에 메모리가 관리가 필요하다.
    - 각각의 프로세스는 독립된 메모리 공간을 갖고, 운영체제 혹은 다른 프로세스의 메모리 공간에 접근할 수 없는 제한이 걸려있다. 단지, 운영체제만이 
    운영체제 메모리 영역과 사용자 메모리 영역의 접근에 제약을 받지 않는다.

### 논리 대 물리주소 공간
```
CPU가 생성하는 주소를 논리 주소, 메모리가 취급하는 주소를 물리 주소라 한다.  

프로그램 실행 중에는 이와 같은 가상 주소를 물리 주소로 바꿔줘야 하는데, 이 매핑 작업은 메모리 관리기(Memory Management Unit)에서 실행된다.

앞으로 다룰 기법들은 이러한 매핑 작업에 대해서 알아보는 것이다.
```
![메모리 매핑](https://user-images.githubusercontent.com/47075043/149686968-c047afb8-eced-4147-b19d-7eeee1b6abb5.png)

## 세그멘테이션

배경

사용자가 인식하는 메모리의 모습과 실제 물리 메모리의 모양은 같지 않다. 물리적 특성을 고려하여 프로그래머가 메모리를 관리하는 방식은 효율적이진 않다. 

그래서 프로그래머가 인지하는 메모리의 모습을 실제 물리 메모리의 모습으로 변환해주는 기법을 제공한다. 시스템은 메모리 관리하는데 있어서 더 많은 자유로운 선택을 할 수 있고, 프로그래머 또한 자연스러운 프로그래밍이 가능하다.


### 기본방법

프로그래머는 메모리를 일부는 명령어를 저장하고, 나머지는 데이터를 저장하는 바이트의 배열로 생각하는가? 아니다. 프로그래머들은 가변적인 길이를 가진 세그먼트의 집합 그리고 세그먼트 사이에는 어떤 순서도 존재하지 않는다고 생각한다.


![논리주소](https://user-images.githubusercontent.com/47075043/149687298-8790ae1b-a020-4d7b-bb9f-f2087cc11bab.png)

프로그래머는 이러한 요소들이 적재되는 주소에 상관업이 '스택' , 'math 라이브러리' , '메인 프로그램' 이라 칭한다. 순서는 신경쓰지 않는것이다. 여기서 세그먼트의 길이는 프로그램의 목적에 따라 자동적으로 결정되게 된다. 각 세그먼트 내의 요소들은 "메인 프로그램의 1번째 명령문" , "심볼 테이블의 17번째 항목" 등과 같은 식의 '변위'로 생각된다.(여기서 변위의 의미는 위치와 양으로 보자)

세그멘테이션이란 위와 같이 프로그래머가 생각하는 모양을 그대로 지원하는 메모리 관리 기법이다. 프로그래머가 생각하는 논리 구조 공간은 세그먼트들의 집합으로 이루어진다. 각 세그먼트는 이름과 길이를 가진다. (프로그램에서 사용되는 주소는 세그먼트 이름과 오프셋의 두 부분으로 나누어 명기한다.) 구현을 쉽기 하기 위해, 내부에서는 세그먼트에 번호가 매겨지며 논리주소는 <세그먼트 번호, 오프셋> 구성으로 된다. C 컴파일러는 다음과 같은 세그먼트들을 만들어 낼 것이다. 

1.코드

2.전역 변수

3.메모리 할당을 위한 힙

4.각 쓰레드를 위한 스택

5.표준 C라이브러리

컴파일 타임에 링크되는 라이브러리는 별도의 세그먼트에 할당되어야 한다. 로더는 이런 세그먼트를 받아서 세그먼트마다 번호를 매긴다.

### 세그먼트 하드웨어

세그먼트 테이블의 각 항목은 세그먼트의 기준(base)과 세그먼트 한계(limit)을 가지고 있다. 세그먼트 기준은 세그먼트 시작 주소를 나타내며, 세그먼트 한계는 세그먼트 길이를 명시한다. 

![세그먼트 하드웨어](https://user-images.githubusercontent.com/47075043/149690317-1fdfa4cd-606d-4e9a-bc69-086d49dddba0.png)

이제 **논리주소는 세그먼트 번호s와 세그먼트 내에서의 변위d(offset)** 로 이루어진다. 세그먼트 번호 s는 세그먼트 테이블에 대한 색인이다. 변위d값은 0과 세그먼트 크기 사이의 값이여야 하며 그렇지 않을 경우 트랩이 발생한다. 
이 변위가 범위 안에 있으면 세그먼트 기준+변위가 원하는 바이트의 실제 주소가 되는 것이다. 예시를 보자. 

![세그멘테이션 예제](https://user-images.githubusercontent.com/47075043/149691251-7a542657-ff7b-479a-b566-3d9a540d17ad.png)

0에서 4까지의 다섯개의 번호를 가진 세그먼트가 있다. 각 세그먼트는 물리 메모리에 저장되어 있고 세그먼트 테이블은 각 세그먼트별 항목을 가지고 있고, 각 항목은 메모리 내의 실제 주소의 시작(base)과 끝(limit)을 나타낸다. 

세그먼트 2는 400B의 길이로, 4300번지부터 시작된다. 즉, 세그먼트 2 내의 53번째 바이트에 대한 참조는 4300+53 = 4353번지로 사상된다. 


## Paging

세그멘테이션은 프로세스가 적재되는 물리 주소 공간이 연속적이지 않아도 적재를 허용한다. 

반면 페이징은 이러한 이점을 제공하는 또 하나의 메모리 기법이다. 

페이징은 외부 단편화를 방지하고, 단편화에 따른 압축 작업이 필요 없지만, 세그멘테이션은 그렇지 않다. 

또한 페이징은 스왑 아웃되는 다양한 크기의 세그먼트를 예비 저장장치에 저장해야 하는 심각한 문제도 해결한다. 

물리 메모리는 프레임이라 불리는 같은 크기의 블록으로 나뉜다. 

반면, 논리 메모리는 페이지라 불리는 같은 크기의 블록으로 나뉜다. 

프로세스가 실행되면서 프로세스의 페이지는 파일 시스템이나 예비저장장치로부터 주 메모리 프레임으로 적재되게 된다. 페이징 하드웨어를 살펴보자. 

![페이지 하드웨어](https://user-images.githubusercontent.com/47075043/149692853-3b21ab83-21da-4118-ac88-2cef41dd3cb5.png)

CPU에서 나오는 모든 주소는 **페이지 번호(p) 와 페이지 변위(d:offset)** 두 개의 부분으로 나뉜다. 페이지 번호는 페이지 테이블에 엑세스 할 때 사용되며 페이지 테이블은 주 메모리에서 각 페이지가 점유하는 주소를 가지고 있다. 이제 이 페이지 주소에 페이지 변위를 더하면 원하는 물리 주소가 된다. 

### 페이지 크기
페이지 크기 역시 하드웨어가 결정한다. 대개의 경우 512B ~ 16MB 사이이며 2의 제곱으로 증가한다. 만약 논리 주소 공간의 크기가 2의m승이고 , 페이지의 크기가 2의 n승이라면 논리 주소의 상위 m-n비트는 페이지 번호를 나타내며, 하위  n비트는 페이지 변위를 나타낸다. 논리 주소가 16, 페이지 크기가4, 물리 메모리 크기가 32인 예를 보자.

논리 주소3은 페이지 0, 변위 3이고 실제 주소는 5*4 + 3 이므로 23번째의 물리 메모리에 저장되어 있다.

![페이징 크기 예시](https://user-images.githubusercontent.com/47075043/149699852-1c68f465-45b8-4fa9-bbfe-dcf4c0a19b30.png)

페이징 그 자체는 동적 재배치이다. 모든 논리 주소는 페이징 하드웨어에 의해 물리 주소로 사상되기 때문이다. 그래서 페이징 기법을 사용하면 외부 단편화는 발생하지 않는다. 놀고있는 모든 프레임이 프로세스에게 할당이 되기 때문인데, 이 때문에 내부 단편화가 발생한다. 할당이 항상 프레임의 정수 배로 할당되기 때문이다. 

따라서 n+1번째 프레임은 거의 모든 프레임에서 내부 단편화가 발생한다. 평균적으로는 프로세스당 반 페이지 정도의 내부 단편화가 예상된다. 작은 페이지 크기가 유리할 수도 있는데, 이는 결국 페이지 테이블이 커지는 문제를 야기한다. 한편 디스크 입장에서는 페이지 크기가 클수록 효율적이다. 일반적 추세는 페이지 크기가 프로세스, 자료, 주 메모리와 함께 커짐에 따라 같이 커져왔다. 


![페이지 프레임 할당](https://user-images.githubusercontent.com/47075043/149699896-16ab242a-4e65-496c-90eb-ae0e00d27af9.png)

그림에서 볼 수 있듯이, 페이징의 가장 큰 특징은 메모리에 대한 프로그래머의 인식과 실제 내용이 다르다는 것이다. 프로그래머는 메모리가 연속된 공간이며 메모리에는 이 프로그램만 있다고 생각하지만, 실제로는 프로그램은 여러 곳에 프레임 단위로 분산되어 있고, 많은 다른 프로그램도 올라와 있다. 논리 주소는 물리 주소로 매핑되며, 이 매핑과정은 프로그래머에게는 안 보이고 OS가 컨트롤한다. 따라서 이용자 프로세스는 자신의 것이 아닌 메모리에는 접근할 수 없다. 

OS는 메모리를 관리하기 위해 물리 메모리의 할당에 대해 파악하고 있어야 한다. 즉 어느 프레임이 할당되어 있고, 어느 프레임이 사용 가능한지, 총 프레임은 몇 개나 되는지 등을 알아야 하며 이러한 정보는 일반적으로 프레임 테이블에 저장된다. (프레임 당 하나의 항목을 가지며 놀고 있는지, 할당되어 있는지, 어느 프로세스의 어느 페이지에 할당되었는지) 

 또한 OS는 프로세스의 논리 주소를 정확한 물리 주소로 매핑해야 하는데, 이를 위해 각 사용자에 대해 페이지 테이블의 복사본을 유지한다. 이 복사본은 시스템 콜을 처리하기 위해 사용자 프로그램의 물리 주소를 알아낼 때 사용되며, 따라서 페이징은 Context Switching 시간을 증가시킨다. 


## Fragmentation(단편화)

```
RAM에서 메모리의 공간이 작은 조각으로 나뉘어져 사용가능한 메모리가 충분히 존재하지만 할당(사용)이 불가능한 상태를 보고 메모리 단편화가 발생했다고 한다.
```
<br>
1. 내부 단편화

- 메모리를 할당할 때 프로세스가 필요한 양보다 더 큰 메모리가 할당되어서 프로세스에서 사용하는 메모리 공간이 낭비 되는 현상

![내부 단편화 image](https://trello-attachments.s3.amazonaws.com/5e8aea3aaf239f64e5fe7306/820x393/d6b06e1de4afa891f98f931148041065/image.png)

메모리를 할당하는 최소 블록 크기를 10K라고 가정합시다.
만약 7K만큼의 공간을 사용하더라도 10K를 할당해야되고 나머지 3K를 낭비하게 됩니다.

<br>
2. 외부 단편화
메모리가 할당 및 해제 작업의 반복으로 작은 메모리가 중간중간에 존재 중간중간에 생긴 사용하지 않는 메모리가 존재해서 총 메모리 공간은 충분하지만 실제로 할당할 수 없는 상황
여유 공간이 여러 조각으로 나뉘는 현상

<br>

![외부 단편화 image](https://trello-attachments.s3.amazonaws.com/5e8aea3aaf239f64e5fe7306/820x347/3113cb036860ef7b97257f0ca5cc9451/image.png)

- 프로세스 A,B,C 사이의 총 8K의 공간이 남아있습니다.
프로세스 D는 7K의 공간을 필요로 하므로, 남은 공간은 충분합니다.
그러나 분할하여 할당할 수 없으므로 프로세스D를 할당할 수 없는 문제가 발생합니다.

---


참고 :

[[10분 테코톡] 🐰 멍토의 Blocking vs Non-Blocking, Sync vs Async](https://www.youtube.com/watch?v=oEIoqGd-Sns)

https://deveric.tistory.com/99

[프로세스 동기화1](https://velog.io/@codemcd/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9COS-8.-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%EB%8F%99%EA%B8%B0%ED%99%94-1)

[프로세스 동기화2](https://dduddublog.tistory.com/25)

https://velog.io/@byunji_jump/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%EB%8F%99%EA%B8%B0%ED%99%94

[반효경 - 운영체제](http://www.kocw.net/home/m/search/kemView.do?kemId=1046323&ar=pop)

[메모리 관리 전략1](https://dduddublog.tistory.com/28)
[메모리 관리 전략2](https://dduddublog.tistory.com/32)

[메모리 단편화](https://junghyun100.github.io/%EB%A9%94%EB%AA%A8%EB%A6%AC%EB%8B%A8%ED%8E%B8%ED%99%94/)