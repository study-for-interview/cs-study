# 가상 메모리
  
  ## 배경
  ``` 
  가상 메모리는 물리 메모리 크기의 한계를 극복하기 위해 나온 기술이다. 즉, 물리 메모리보다 큰 프로세스를 수행하기 위해 가상 메모리를 사용한다. 

  예를 들어, 100MB 메모리 크기에서 200MB 크기의 프로세스를 수행할 수 있도록 하는 것이다.

  이러한 방식이 어떻게 가능할까? 필요한 부분만 메모리에 적재하는 것이다. 프로세스를 실행할 때, 실행에 필요한 부분만 메모리에 올리는 것이다. 
  
  이러한 프로세스의 일부분은 페이지 단위일 수도 있고, 세그먼트 단위일 수도 있지만 현재 대부분은 페이지 단위를 사용한다. 이처럼 현재 필요한(요구되어지는) 페이지만 메모리에 올리는 것을 Demanding Paging(요구 페이징) 이라고 한다.
  ```

  ## 가상 메모리가 하는 일
  ```
가상 메모리는 실제의 물리 메모리 개념과 사용자의 논리 메모리 개념을 분리한 것으로 정리할 수 있다. 이로써 작은 메모리를 가지고도 얼마든지 큰 가상 주소 공간을 프로그래머에게 제공할 수 있다.
  ```
  
가상 메모리의 기본 아이디어는 프로세스는 가상 주소를 사용하고, 데이터를 사용(읽고/쓰기) 할 때 물리 주소로 변환해주면 된다는 것이다.

즉, 가상 메모리 시스템을 사용하기 위해서는 가상 주소(virtual address)와 물리 주소(physical address)가 필요하다.
- virtual address(가상 주소): 프로세스가 참조하는 주소
- physical address(물리 주소): 실제 메모리 주소


### 가상 주소 공간
- 한 프로세스가 메모리에 저장되는 논리적인 모습을 가상메모리에 구현한 공간이다. 프로세스가 요구하는 메모리 공간을 가상메모리에서 제공함으로써 현재 직접적으로 필요치 않은 메모리 공간은 실제 물리 메모리에 올리지 않는 것으로 물리 메모리를 절약할 수 있다.

- 예를 들어, 한 프로그램이 실행되며 논리 메모리로 100KB 가 요구되었다고 하자. 하지만 실행까지에 필요한 메모리 공간(Heap영역, Stack 영역, 코드, 데이터)의 합이 40KB 라면, 실제 물리 메모리에는 40KB 만 올라가 있고, 나머지 60KB 만큼은 필요시에 물리메모리에 요구한다고 이해할 수 있겠다.

![image](https://user-images.githubusercontent.com/47075043/150214550-8cf186bd-28bd-41d9-bb9d-52492b964f31.png)

가상메모리에서 실제 physical memory에 올라가는 부분과 올라가지 않는 부분을 memory map에 표현을 한다.

  ## Demand Paging (요구 페이징)
```
프로세스 전체가 메모리 내에 올라와야 하는 메모리 관리 기법 방식의 대안으로 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법을 가상메모리라고 한다.

그 중 요구페이징은 필요한 프로그램만 메모리에 적재하는 방법으로 가상 메모리 시스템에서 많이 사용된다. 
요구 페이징을 사용하는 가상메모리에서는 페이지들이 실행 과정에서 실제로 필요해질 때 적재 된다.
```

요구 페이징에서는 하나의 프로세스의 페이지가 일부는 메모리 위, 일부는 보조 저장 장치에 있습니다.
이 두 상황을 구분하기 위해 valid - invalid 비트를 사용합니다.

- valid: the page is both legal and in memory.(메모리 위에 있는 상태를 나타냄)
- invalid: the either is not valid or currently in secondary storage.(메모리 위에 있지 않은 상태를 나타냄)

![image](https://user-images.githubusercontent.com/47075043/150216146-65976f2d-6e5c-48e2-a635-6f5cba69055c.png)

1.2. Page Fault(페이지 부재)
페이지 부재는 위에서 살펴본 CPU가 접근하려는 페이지가 메모리에 없는 경우이다. 즉, 페이지 테이블의 valid bit값이 0인 경우이다.


## 페이지 폴트(Page Fault)

- 페이지 폴트란 프로그램이 자신의 주소 공간(가상메모리공간)에는 존재하지만 시스템의 RAM에는 현재 없는 데이터나 코드에 접근 시도하였을 경우 발생하는 현상을 말한다.

페이지 폴트가 발생하면 운영체제는 그 데이터를 메모리로 가져와서 마치 페이지 폴트가 전혀 발생하지 않은 것처럼 프로그램이 계속적으로 동작하게 해준다.

페이지 부재 처리 과정 : 

1. 프로세스에 대한 내부테이블을 검사해서 그 메모리 참조가 유효/무효 인지 알아 낸다.
2. 참조가 유효한 경우(valid) 프로세스를 종료하고, 무효한 참조인 경우(invalid) 메모리에 없으면 디스크로부터 가져와야 한다.
3. 빈 공간, 자유 프레임(free frame)을 찾는다.
4. 디스크에 새로이 할당된 프레임으로 해당 페이지를 읽어 들이도록 요청
5. 디스크 읽기가 끝나면 이 페이지가 메모리에 있다는 것을 알리기 위해 페이지 테이블을 갱신하며 프로세스가 유지되고 있는 내부테이블을 수정한다.
6. 트랩에 의해 중단되었던 명령을 다시 수행하며 프로세스는 그 페이지가 항상 메모리에 있엇던 것처럼 간주하여 해당 페이지를 접근할 수 있다.

![image](https://user-images.githubusercontent.com/47075043/150216880-0197135f-6031-4922-a0f2-b9536aa3d5c5.png)

### Page Replacement

만약 page fault가 일어났는데 free frame이 없는 경우 Page Replacement을 해야합니다.
- 빈 프레임이 없으면
    - 현재 사용중이 아닌 것을 찾아 free frame으로 만듭니다.
- 스왑 공간에 내용을 기록하고 프레임을 확보합니다.
    - 페이지 표를 변경합니다.
    - 페이지가 더이상 메모리에 없음을 나타냄(invalid or dirty)
- 이제 free frame에 사용하고자 하는 페이지를 메모리에 올립니다.

![image](https://user-images.githubusercontent.com/47075043/150220636-28009596-1e5f-425b-9e37-e3ef7f64df94.png)

--- 

## Page-replacement algorithm
```
교체할 프레임을 선택하는 알고리즘으로 보조 스토리지와 I/O 작업은 리소스가 매우 비싸기 때문에 요구 페이징 방식의 개선이 이루어지면 시스템 성능에서 큰 이득을 얻을 수 있습니다.
```

### 페이지 교체 알고리즘 평가 : 
- 페이지 폴트 수를 계산합니다. (최소화!)
- 페이지 프레임 수가 많을수록 페이지 fault 수는 줄어듭니다.

![image](https://user-images.githubusercontent.com/47075043/150230247-5af27102-0609-4450-af38-62e40486aedc.png)

### 알고리즘 평가 예시)

![image](https://user-images.githubusercontent.com/47075043/150230441-8a2d5bf0-ae8a-4eb4-a9e4-c9e00b70a066.png)

# Page Replacement 알고리즘 종류

## FIFO 방식
- 가장 단순한 방식의 알고리즘으로 가장 오래된 페이지를 교체하는 방식
- 예시에서는 15번의 page fault가 일어난다.
![image](https://user-images.githubusercontent.com/47075043/150230768-6a450a6a-3d9b-4569-9c46-ebc6044e7f34.png)

- 단점으로 Balady의 모순이 있다. 
    - 원래 페이지 프레임 수가 늘어나면 페이지 부재가 더 적게 발생해야 하는데 페이지 프레임 수가 늘어났음에도 불구하고 페이지 부재가 더 많이 발생하는 모순이 생기는 경우가 있다.

![image](https://user-images.githubusercontent.com/47075043/150230937-1a0bce6c-89e2-419f-a778-771effe82a62.png)

## OPT(Optimal Page Replacement)
- 페이지 부재가 가장 낮은 알고리즘이고 Belady의 변칙과 같은 상황이 일어나지 않습니다.
- 방식은 가장 오랫동안 사용하지 않을 페이지를 교체하기 때문에 가장 낮은 페이지 부재를 보장합니다.
- 그러나 OPT는 구현이 어렵기 때문에 주로 다른 알고리즘이 이 OPT 알고리즘과 비교하는 대상에 사용됩니다.

![image](https://user-images.githubusercontent.com/47075043/150231311-3e31f5ee-e8ea-4477-945b-129baf15e7f7.png)

## LRU(Least Recently Used Page Replacement) 
- 최적 알고리즘과 가장 가까운 알고리즘으로, 가장 오랫동안 사용되지 않은 페이지를 교체하는 알고리즘입니다.
- 성능에 좋은 편이지만 LRU의 구현을 위해서 마지막 사용시간을 나타내기 위해 하드웨어의 지원이 필요할 수 있습니다.
- 카운터와 스택을 이용하여 두 가지 방법으로 구현이 가능.

![image](https://user-images.githubusercontent.com/47075043/150231568-2adce911-f7dc-4efa-afac-a81a8bc3bf2e.png)

--- 

## 쓰레싱(Thrashing)이란?

- 페이지 부재가 과도하게 발생하는 상황에서 프로세스의 실행보다 페이징을 위해 더 많은 시간이 소요되는 현상.

쓰레싱의 원인
- CPU 이용률이 떨어질 때 새로운 프로세스를 추가하여 멀티 프로그래밍 정도(degree)를 높이려 하기 때문
- 멀티 프로그래밍 정도가 과도하게 높아지면
    - 프로세스의 프레임 개수 감소하고 페이지 부재 증가
    - 입출력 대기가 길어져서 CPU 이용율 감소
    - 새로운 프로세스를 시작
        - 페이지 부재 증가와 CPU 이용률 감소가 악순환됨


지역교환 알고리즘 or 우선순위 교환 알고리즘

- 지역교환 알고리즘하에서는 한 프로세스가 쓰레싱을 유발하더라도 다른 프로세스로부터 프레임을 뺏어 올 수 없으므로, 다른 프로세스는 쓰레싱으로부터 자유로울 수 있다.

쓰레싱 현상 방지 방법

- 각 프로세스가 필요로 하는 최소한의 프레임 갯수를 보장해주어야 합니다.
- CPU의 이용률을 높이고 쓰레싱현상을 방지하기 위해서는 다중 프로그래밍의 정도를 낮추어야 합니다.
    - 즉, 각 프로세스들에게 충분한 페이지 프레임을 할당할 수 있도록 해 주거나
    - 주기억 장치 내에 워킹 세트(Working set)을 제대로 유지하는 한 스레싱이 방지된다.
        - working set : 임의의 시점에 집중적으로 참조되는 페이지들을 모두 주기억장치에 적재시켜 프로세스로 하여금 페이지 부재를 거의 발생시키지 않도록 하는 set, 이 기법은 프로세스가 현재 시간 이후에도 어느 정도 시간 동안은 이 집합에 속한 페이지들을 집중적으로 참조할 것이라는 지역성을 기반으로 한다.

![image](https://user-images.githubusercontent.com/47075043/150232682-9ffc1662-0e66-4cf5-98d0-cb0cab5cc340.png)



참고: 

https://slenderankle.tistory.com/189 [SLENDER ANKLES's 개발블로그]

http://itnovice1.blogspot.com/2019/08/thrashing.html

https://www.inflearn.com/course/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%EA%B3%B5%EB%A3%A1%EC%B1%85-%EC%A0%84%EA%B3%B5%EA%B0%95%EC%9D%98/dashboard

---
# 캐시 메모리
```
캐시 메모리(Cache Memory)는 속도가 빠른 장치와 느린 장치 간의 속도차에 따른 병목 현상을 줄이기 위한 범용 메모리다.

메인 메모리와 CPU 사이에 위치하며, CPU의 속도에 버금갈 만큼 메모리 계층에서 가장 속도가 빠르지만, 용량이 적고 비싸다는 점도 있다. 

캐시 메모리는 메인 메모리에서 자주 사용하는 프로그램과 데이터를 저장해두어 속도를 빠르게 한다. 이를 위해서 CPU가 어떤 데이터를 원하는지 어느 정도 예측할 수 있어야 한다. 작은 크기의 캐시 메모리에 CPU가 이후에 참조할 정보가 어느 정도 들어있는지에 따라 캐시의 성능이 결정되기 때문이다. 

이를 위해 캐시의 지역성(Locality)을 이용한다. 
```

## 캐시의 지역성
---
캐시의 지역성(Cache Locality)이란, 데이터에 대한 접근이 시간적 혹은 공간적으로 가깝게 발생하는 것을 말한다. 캐시의 적중률(Hit rate)을 극대화하여 캐시가 효율적으로 동작하기 위해 사용되는 성질이다. 

지역성의 전제조건으로, 프로그램은 모든 코드나 데이터를 균등하게 접근하지 않는다는 특성을 기본으로 한다. 

캐시의 지역성은 **공간 지역성(Spatial Locality)과 시간 지역성(Temporal Locality)**으로 나뉜다. 

공간 지역성 : 최근에 사용했던 데이터와 인접한 데이터가 참조될 가능성이 높다는 특성
시간 지역성 : 최근에 사용했던 데이터가 재참조될 가능성이 높은 특성 

공간 지역성은 배열을 예로 들 수 있다. A[0], A[1]과 같은 연속 접근의 경우 그 다음 원소들에 접근할 가능성이 높다. 

시간 지역성은 for, while 같은 반복문을 예로 들 수 있다. 특정 부분을 반복해서 접근하기 때문에 다시 참조할 확률이 높다.


## Caching line
---

캐시 메모리는 메인 메모리에 비해 크기가 매우 작기 때문에 메인 메모리와 1:1 매칭이 불가능하다.

캐시가 아무리 CPU에 가깝게 위치하더라도, 데이터가 캐시 내의 어느 곳에 저장되어 있는지 찾기가 어려워 모든 데이터를 순회해야 한다면 캐시의 장점을 잃기 때문에 쉽게 찾을 수 있는 구조가 필요하다.

따라서, 캐시에 데이터를 저장할 때 특정 자료구조를 사용하여 묶음으로 저장하는데, 이를 캐싱 라인(Caching Line)이라고 한다. 빈번하게 사용되는 데이터의 주소들이 흩어져 있기 때문에 캐시에 저장하는 데이터에는 데이터의 주소 등을 기록해둔 태그를 달아둘 필요가 있다. 이러한 태그들의 묶음을 의미한다. 

캐싱 라인은 다음과 같은 매핑 방법을 사용한다. 

## 1. Direct Mapping
```
직접 매핑으로, 메인 메모리를 일정한 크기의 블록으로 나누어 각각의 블록을 캐시의 정해진 위치에 매핑하는 방식이다. 가장 간단하고 구현도 쉽다.

하지만 적중률(Hit rate)이 낮아질 수 있다. 또 동일한 캐시 메모리에 할당된 여러 데이터를 사용할 때 충돌이 발생하게 되는 단점이 있다.
```
![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FKWMR2%2FbtrgjyIn1ns%2FmvER1WQu1w7kI4BuHbQCqk%2Fimg.png)

## 2. Full Associative Mapping
```
캐시 메모리의 빈 공간에 마음대로 주소를 저장하는 방식이다. 저장하는 것은 매우 간단하지만, 원하는 데이터가 있는지 찾기 위해서는 모든 태그를 병렬적으로 검사해야 하기 때문에 복잡하고 비용이 높다는 단점이 있다. 
```

## 3. Set Associative Mapping
```
Direct Mapping과 Full Associative Mapping의 장점을 결합한 방식이다. 

빈 공간에 마음대로 주소를 저장하되, 미리 정해둔 특정 행에만 저장하는 방식이다. Direct에 비해 검색 속도는 느리지만 저장이 빠르고 Full에 비해 저장이 느리지만 검색은 빠르다. 

주로 사용하는 방식이다. 
```

## 4. Cache Miss
```
캐시 미스(Cache Miss)는 CPU가 참조하려는 데이터가 캐시 메모리에 없을 때 발생한다. 
```
 
1) Compulsory Miss

- 특정 데이터에 처음 접근할 때 발생하는 cache miss이다.

2) Capacity Miss 

- 캐시 메모리의 공간이 부족해서 발생하는 cache miss이다.

3) Conflict Miss

- 캐시 메모리에 A와 B 데이터를 저장해야 하는데, A와 B가 같은 캐시 메모리 주소에 할당되어 있어서 발생하는 cache miss이다. direct mapped cache에서 많이 발생한다. 

참고 : 

https://rebro.kr/180 [Rebro의 코딩 일기장]