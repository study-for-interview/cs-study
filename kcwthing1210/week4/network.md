# 🎁 TCP 3 way handshake & 4 way handshake
# 📌 TCP 3 way handshake
## ✔ 개념
TCP/IP 프로토콜을 이용해서 통신을 하는 응용 프로그램이 데이터를 전송하기 전에 정확한 전송을 보장하기 위해 상대방과 사전에 세션을 수립하는 과정(연결이 잘 되었는지 확인하는 과정)
TCP가 연결지향적인 특성을 갖게 해준다.

## ✔ 역할
- 양쪽 모두 데이터를 전송할 준비가 되었다는 것을 보장
- 양쪽 모두 상대방에 대한 초기 순차 일련번호를 얻을 수 있도록 한다.
- 3번의 신호를 주고 받아서 3-way-handshaking

## ✔ 과정
![](https://images.velog.io/images/kcwthing1210/post/9119fd2c-a115-4847-8458-6f803a25b788/image.png)

1) Client -> Server
- 서버에 접속을 요청하는 SYN 패킷 전송
- 송신자가 최초로 데이터를 전송할 때 Sequence Number를 임의의 랜덤 숫자로 지정, SYN 플래그 비트를 1로 설정한 세그먼트 전송
- 클라이언트는 SYN/ACK 응답을 기다리는 SYN_SENT 상태가 된다.

2) Server -> Client
- 서버는 클라이언트에게 요청을 수락(ACK)했으며 접속 요청 프로세스인 클 라이언트도 포트를 열어달라(SYN)는 메세지 전송
- 서버는 SYN_RECEIVED 상태가 된다.

3) Client -> Server
- 클라이언트는 서버에게 ACK를 보내고 이후에는 연결 완료
- 전송할 데이터가 있으면 전송 가능
- ESTABLISHED 상태가 된다.

![](https://images.velog.io/images/kcwthing1210/post/ea35d010-4460-4c3c-af86-4b397f196ca5/image.png)

# 📌 4 way handshake

## ✔ 개념
- 세션을 종료하기 위해 수행되는 과정

## ✔ 과정
![](https://images.velog.io/images/kcwthing1210/post/ef9a936f-6896-4718-9996-72507e675eb1/image.png)

1) Client -> Server
- 클라이언트가 연결을 종료하겠다는 FIN 플래그 전송
- 서버가 FIN 플래그로 응답하기 전까지 연결 유지

2) Server -> Client
- 서버는 일단 확인 메세지(ACK)를 보내고 자신의 통신이 끝날 때까지 대기

3) Server -> Client
- 서버가 통신이 끝났으면 연결 종료되었다고 클라이언트에게 FIN 플래그 전송

4) Client -> Server
- 클라이언트는 확인했다는 메세지 전송
- 서버 연결 CLOSED

![](https://images.velog.io/images/kcwthing1210/post/a5826cd1-72c9-4cbe-ae16-5c9cef4bfc78/image.png)


![](https://images.velog.io/images/kcwthing1210/post/ded3bf32-341d-434c-9926-904e23682c4a/image.png)


## ❗ Q&A
Q. TCP의 연결 설정 과정(3단계)과 연결 종료 과정(4단계)이 단계가 차이나는 이유?
A. Client가 전송할 데이터가 없다고해도 Server에서 보내야하는 데이터가 아직 남아있을 수 있기때문에 우선 FIN에 대한 ACK를 먼저 보내고 남은 데이터 전송 후에 FIN을 보낸다.

Q. 만약 Server에서 FIN 플래그를 전송하기 전에 전송한 패킷이 Routing 지연이나 패킷 유실로 인한 재전송 등으로 인해 FIN 패킷보다 늦게 도착하는 상황이 발생하면 어떻게 될까?
A. Client에서 세션을 종료시킨 후 늦게 도착하는 패킷은 drop되고 데이터는 유실된다. 이런 상황에 대비하여 Client는 Server로부터 FIN을 수신하고 일정시간(default 240sec)동안 세션을 남겨두고 잉여 패킷을 기다린다. (TIME_WAIT 과정)

Q. 초기 Sequence Number인 ISN을 0부터 시작하지 않고 난수를 생성해서 설정하는 이유?
초기 Sequence Number를 ISN(Initial Sequence Number)이라고 한다.
A1. Connection을 맺을 때 사용하는 Port는 유효한 범위 내에서 사용하고 시간이 지남에 따라 재사용
-> 두 통신 호스트가 과거에 사용된 Port 번호 쌍을 사용하는 가능성 존재
Server에서는 SYN을 보고 패킷을 구분, 난수가 아닌 순차적 Number가 전송된다면 이전 Connection으로부터 오는 패킷으로 인식할 수 있다. 이런 문제 가능성을 줄이기 위해 난수로 ISN 설정

A2. 0에서 시작하는 ISN은 이어지는 Seq를 쉽게 예측하게 만들어 공격에 취약해진다.

# 🧩 Reference
- https://velog.io/@arielgv829/CS-network-TCP-3-way-handshake-4-way-handshake

- https://seongonion.tistory.com/74


# 🎁 TCP/IP 흐름제어 & 혼잡제어
# 📌 흐름제어
## ✅ 개념
- 송신측과 수신측의 데이터 처리 속도 차이를 해결하기 위한 기법.
- 송신측의 데이터 **전송량** 제어

## ✅ 흐름제어 기법
### ✔ Stop & Wait 방식
- 매번 전송한 패킷에 대해 확인 응답을 받아야만 그 다음 패킷을 전송하는 방법 (비효율적)

### ✔ Sliding window
- 수신 측에서 설정한 윈도우 크기만큼 송신 측에서 확인 응답(ACK) 없이 패킷을 전송할 수 있게 하여 데이터 흐름을 동적으로 조절하는 제어 기법
- 송신 버퍼의 범위는 수신 측의 여유 버퍼 공간을 반영하여 동적으로 바뀜.

#### (1) 윈도우 크기
최초의 윈도우 크기는 호스트들의 '3 way handshaking'을 통해 수신 측 윈도우 크기로 설정되며, 이후 수신 측의 버퍼에 남아있는 공간에 따라 변한다. 윈도우 크기는 수신 측에서 송신 측으로 확인 응답(ACK)을 보낼 때 TCP 헤더(window size)에 담아서 보낸다. 즉, 윈도우는 메모리 버퍼의 일정 영역이라고 생각하면 된다.
#### (2) 동작 방식
윈도우에 포함된 패킷을 계속 전송하고, 수신 측으로부터 확인 응답(ACK)이 오면 윈도우를 옆으로 옮겨 다음 패킷들을 전송한다.


![](https://images.velog.io/images/kcwthing1210/post/e567d513-d3c9-4433-8960-b9af20e48752/image.png)

- 최초로 수신자는 윈도우 사이즈를 7로 정한다.
- 송신자는 수신자의 확인 응답(ACK)을 받기 전까지 데이터를 보낸다.
- 수신자는 확인 응답(ACK)을 송신자에게 보내면, 슬라이딩 윈도우 사이즈을 충족할 수 있게끔 윈도우를 옆으로 옮긴다
- 이후 데이터를 다 받을 때까지 위 과정을 반복한다.

#### (3) 재전송
송신 측은 일정 시간 동안 수신 측으로부터 확인 응답(ACK)을 받지 못하면, 패킷을 재전송한다. 만약, 송신 측에서 재전송을 했는데 패킷이 소실된 경우가 아니라 수신 측의 버퍼에 남는 공간 없는 경우면 문제가 생긴다. 이를 해결하기 위해 송신 측은 해결 응답(ACK)을 보내면서 남은 버퍼의 크기 (윈도우 크기)도 함께 보내 준다.

# 📌 혼잡제어

## ✅ 개념
- 송신측의 데이터 전달과 네트워크 상의 데이터 처리 속도 차이를 해결하기 위한 기법.
- 송신측의 데이터 전송 속도 제어
- 데이터의 양이 라우터가 처리할 수 있는 양을 초과하면 초과된 데이터는 라우터가 처리하지 못한다. 이때 송신 측에서는 라우터가 처리하지 못한 데이터를 손실 데이터로 간주하고 계속 재전송하여 네트워크를 혼잡하게 한다. 이런 상황은 송신 측의 전송 속도를 적절히 조절하여 예방할 수 있는데, 이것을 혼잡 제어라고 한다.

## ✅ 혼잡제어 기법

### ✔ AIMD (Additive Increase Multicative Decrease)

- 합 증가/ 곱 감소 알고리즘
- 처음에 패킷 하나를 보내는 것으로 시작, 전송한 패킷이 문제 없이 도착하면 윈도우 크기를 1씩 증가시키며 전송
- 패킷 전송을 실패하거나 타임아웃이 발생하면 윈도우 크기를 절반으로 감소시킴
- 여러 호스트가 한 네트워크를 공유하고 있으면 나중에 진입하는 쪽이 처음에는 불리하지만, 시간이 흐르면 평형 상태로 수렴
- 문제점
    - 초기 네트워크의 높은 대역폭을 사용하지 못함
    - 처음에 전송 속도를 올리는 데 시간이 너무 오래 걸림
    - 네트워크가 혼잡해지는 상황을 미리 감지하지 못하여 혼잡해지고 나서야 대역폭을 줄임

  ![](https://images.velog.io/images/kcwthing1210/post/42efdfe7-f36d-4fe2-a82e-9f9f748f74d9/image.png)

### ✔ Slow start

- AIMD와 같이 패킷을 하나씩 보냄
- 하나의 패킷이 문제없이 도착하여 ACK를 보낼 때마다 윈도우 크기를 1씩 늘림
- 한 주기가 지나면 윈도우 크기는 2배 -> 그래프의 모양이 지수함수 꼴
- 혼잡 현상이 발생하면 윈도우 크기를 1로 떨어트림
- 한 번 혼잡 현상이 발생하고 나면 이전에 혼잡 현상이 발생했던 윈도우 크기의 절반까지는 이전처럼 지수함수 꼴로 윈도우 크기를 증가시키고 그 이후부터는 완만하게 1씩 증가시킴

![](https://images.velog.io/images/kcwthing1210/post/73d5164e-6258-4ed0-81a2-6ec7200e52e6/image.png)

### ✔ Fast Recovery

- 혼잡 상태가 되면 윈도우 크기를 1로 줄이지 않고 반으로 줄인 후 선형증가.
- 혼잡 상태를 한 번 겪고 나서부터는 AIMD 방식으로 동작

### ✔ Fast Retransmit

- 먼저 도착해야 할 패킷이 도착하지 않고 다음 패킷이 도착한 경우에도 ACK패킷을 보냄
- 순서대로 잘 도착한 마지막 패킷의 다음 패킷 순번을 ACK패킷에 실어보내게 되므로 송신측에서는 순번이 중복된 것을 알게됨
- 이것을 감지하여 중복된 순번의 패킷을 3개 받으면 타임아웃 전에 문제가 되는 순번의 패킷을 즉시 재전송해줌
- 이런 현상이 일어나면 혼잡 현상이 발생한 것이므로 윈도우 크기를 줄임

## ✅  혼잡 제어 정책
### ✔ 기본용어 정리
#### (1) Timeout

말 그대로 여러 가지 요인으로 인해 송신 측이 보낸 데이터 자체가 유실되었거나, 수신 측이 응답으로 보낸 ACK가 유실되는 경우를 뜻한다.



#### (2) 3 ACK Duplicate

패킷을 받는 수신자 입장에서는 세그먼트로 분할된 내용들이 순서대로 도착하지 않는 경우가 생길 수 있다. 이런 상황이 발생했을 때 수신 측에서는 순서대로 잘 도착한 마지막 패킷의 다음 순번을 ACK 패킷에 실어서 보낸다. 그리고 이런 중복 ACK 3개를 받으면 문제가 있다고 판단하여 해당 패킷을 송신 측이 재전송한다.

![](https://images.velog.io/images/kcwthing1210/post/0e8d8a0f-659b-4bec-a175-b1f65c52a14c/image.png)

당 기법을 빠른 재전송 이라고 부르며, 송신 측은 자신이 설정한 타임 아웃 시간이 지나지 않았어도 바로 해당 패킷을 재전송할 수 있기 때문에 보다 빠른 전송률을 유지할 수 있게 된다.


#### (3) Slow Start 임계점 (ssthresh)

Tahoe와 Reno를 비교하는 그래프를 보면 Threshold(임계점) 이라는 단어가 등장한다. 이 임계점은 Slow Start Threshold(ssthresh) 를 뜻하는 것으로, 여기까지만 Slow Start를 사용하겠다는 의미를 가진다.

![](https://images.velog.io/images/kcwthing1210/post/b8b25129-9808-461c-8af2-cb62ceb19b8d/image.png)

low Start를 사용하며 윈도우 크기를 지수적으로 증가시키다보면 어느 순간부터는 윈도우 크기가 기하급수적으로 늘어나서 제어하기가 힘들다. 또한, 네트워크의 혼잡이 예상되는 상황에서 빠르게 값을 증가시키기 보다는 조금씩 증가시키는 편이 훨씬 안전하다.

쉽게 생각해서 현재 윈도우 크기가 10이고, 현재 네트워크에 남은 공간이 15라고 할 때, Slow Start 방식을 사용하면 윈도우 크기가 20이 되지만 AIMD를 사용하면 앞으로 5번은 윈도우 크기를 천천히 늘릴 수 있다.

그래서 특정한 임계점을 정해 놓고, 그 임계점이 넘어가면 AIMD 방식을 사용하여 선형적으로 윈도우를 증가시킨다. 이때, 이 임계점을 Slow Start Threshold (ssthresh)라고 부른다.


### ✔ TCP Tahoe

- 처음에는 Slow Start 방식을 사용하다가 임계점에 도달하면 AIMD 방식 사용
- 그러다 3 ACK 순번 중복(중간패킷유실)이나 타임아웃이 발생하면 혼잡이라고 판단하여 임계점은 혼잡이 발생한 윈도우 크기의 절반으로, 윈도우 크기는 1로 줄임

![](https://images.velog.io/images/kcwthing1210/post/593bf082-d09e-4190-9cc9-ef153987c2e8/image.png)

위 그래프에서 청록색 선은 송신 측의 혼잡 윈도우 크기를, 굵은 검정선은 ssthresh 값을 보여주고 있다. 이 시나리오에서 송신 측의 혼잡 윈도우 크기는 8로 초기화 되었고, 그에 따라 ssthresh는 4로 설정되어 있다.

송신 측은 임계점을 만나기 전까지 Slow Start 방식을 사용하여 자신의 윈도우 크기를 증가시키다가 ssthresh를 넘어선 이후부터는 선형적으로 증가시키고 있다. 이 상황에서 3 ACK Duplicated나 Timeout과 같은 혼잡 상황을 만나면 어떻게 될까?

그래프를 보면 처음 혼잡 상황이 발생한 상태의 혼잡 윈도우 크기는 6이며, 그에 따라 ssthresh를 3으로 변경하고, 자신의 혼잡 윈도우 크기를 1로 줄였다. 이후 다시 Slow Start로 시작하여 임계점에 도달하면 AIMD를 시작한다.

이 정책은 한 번 혼잡 상황이 발생한 지점을 기억하고 그 지점이 가까워지지 않도록 합리적으로 조절하고 있다. 하지만, 초반의 Slow Start 구간에 윈도우 크기를 늘릴 때 오래 걸린다는 단점이 있고, 혼잡 상황이 발생했을 때 다시 윈도우 크기를 1에서부터 시작해야 한다는 단점이 있다.

### ✔ TCP Reno

- Tahoe와 마찬가지로 slow start로 시작하여 임계점 이후에는AIMD방식으로 변경.
- 단, 3 ACK 중복과 타임아웃을 구분함
- 3 ACK 중복이 발생하면 Fast Recovery 방식을 사용
- 윈도우 크기를 1로 줄이는 것이 아니라 반으로 줄인 후 윈도우 크기를 선형적으로 증가시킴.
- 임계점은 줄어든 윈도우 값으로 설정
- 타임아웃이 발생하면 Tahoe와 마찬가지로 윈도우 1로 줄이고 Slow start 진행.(임계점 변경하지 x)

![](https://images.velog.io/images/kcwthing1210/post/530f52c3-b300-4e57-8df1-e730f4f139ba/image.png)

Reno는 3개의 중복 ACK가 발생했을 때, 윈도우 크기를 1로 줄이는 것이 아니라 AIMD처럼 반으로만 줄이고 sshthresh를 줄어든 윈도우 값으로 정하게 된다. 이 방식을 빠른 회복이라고 부른다.

그러나 Timeout에 의해서 데이터가 손실되면 Tahoe와 마찬가지로 윈도우 크기를 바로 1로 줄여버리고 Slow Start를 진행한다. 이때 ssthresh를 변경하지는 않는다.

즉, Reno는 ACK 중복은 Timeout에 비해 그리 큰 혼잡이 아니라고 가정하고 혼잡 윈도우 크기를 1로 줄이지도 않는다는 점에서 혼잡 상황의 우선 순위를 둔 정책이라 볼 수 있다.


# 🟣 Q&A
**1. TCP/IP 통신에서 흐름 제어 기법이 왜 사용되는가?**
송 수신자 간의 TCP 버퍼의 크기 차이로 인해 생기는 데이터 처리 속도 차이를 해결하기 위해 사용된다.



**2. TCP/IP 흐름 제어 기법은 무엇이 있는가?**
Stop and Wait과 Sliding Window 기법이 있다. Stop and Wait은 전송한 패킷에 대해 확인 응답(ACK)을 받으면 다음 패킷을 전송하는 제어 기법이고, Sliding Window는 수신 측에서 설정한 윈도우 크기만큼 송신 측에서 확인 응답(ACK) 없이 패킷을 전송할 수 있게 하여 데이터 흐름을 동적으로 조절하는 제어 기법이다.



**3. TCP/IP 혼잡 제어 기법이 왜 사용되는가?**
송신 측에서 보내는 데이터의 양이 라우터가 처리할 수 있는 양을 초과하면 초과된 데이터는 라우터가 처리하지 못한다. 송신 측은 초과된 데이터를 손실 데이터로 간주하고 계속 재전송하여 네트워크를 혼잡하게 한다. 이런 상황을 예방하기 위해 송신 측의 전송 속도를 적절히 조절하는 혼잡 제어 기법이 사용된다. 대표적으로 AIMD, Slow Start, 빠른 재전송, 빠른 회복 등이 있다.



**4. TCP/IP 혼잡 제어 정책은 무엇이 있는가?**
대표적으로 TCP Tahoe와 TCP Reno가 있다. TCP Tahoe는 처음에는 Slow Start를 사용하여 자신의 윈도우 크기를 지수적으로 빠르게 증가시키다가 ssthresh를 만난 이후부터는 AIMD을 사용하여 선형적으로 윈도우 크기를 증가시킨다. 반면, TCP Reno는 Tahoe와 마찬가지로 Slow Start로 시작하여 임계점을 넘어서면 AIMD을 사용하되, Tahoe와 다르게 3 ACK Duplicated와 Timeout 혼잡 상황을 구분한다.

# 🧩 Reference
- https://steady-coding.tistory.com/507
- https://doh-an.tistory.com/29

# 🎁 UDP
# 📌 TCP
## ✅ TCP란?
- Transmission Control Protocol
- 전송을 제어하는 프로토콜(규약)
-  인터넷상에서 데이터를 메세지의 형태로 보내기 위해 IP와 함께 사용하는 프로토콜


## ✅ 동작원리
- 일반적으로 TCP와 IP를 함께 사용하는데, IP가 데이터의 배달을 처리한다면 TCP는 *패킷을 추적 및 관리하게 된다.

- TCP는 연결형 서비스를 지원하는 프로토콜로 인터넷 환경에서 기본으로 사용

![](https://images.velog.io/images/kcwthing1210/post/49cb0a6d-c365-4471-bbe5-575bee70b6cc/image.png)





## ✅ 특징
- 연결형 서비스로 가상 회선 방식을 제공한다.

- 3-way handshaking과정을 통해 연결을 설정하고 4-way handshaking을 통해 해제한다.

- 흐름 제어 및 혼잡 제어.

- 높은 신뢰성을 보장한다.

- UDP보다 속도가 느리다.

- 전이중(Full-Duplex), 점대점(Point to Point) 방식.



TCP가 가상 회선 방식을 제공한다는 것은 발신지와 수신지를 연결하여 패킷을 전송하기 위한 논리적 경로를 배정한다는 말이다. 그리고 3-way handshaking과정은 목적지와 수신지를 확실히 하여 정확한 전송을 보장하기 위해서 세션을 수립하는 과정을 의미한다. TCP가 이러한 특징을 지니는 이유는 간단명료한다.

바로 TCP는 연결형 서비스로 신뢰성을 보장하기 때문이다. 그래서 3-way handshaking의 과정도 사용하는 것이고, 데이터의 흐름제어나 혼잡 제어와 같은 기능도 사용한다. 하지만 이러한 기능때문에 UDP보다 속도가 느리게 된다. (이러한 기능은 CPU를 사용하기 때문에 속도에 영향을 줌)

그렇기에 TCP는 연속성보다 신뢰성있는 전송이 중요할 때에 사용하는 프로토콜로 예를 들면 파일 전송과 같은 경우에 사용된다.


## ✅ TCP 서버의 특징
- 서버소켓은 연결만을 담당한다.

- 연결과정에서 반환된 클라이언트 소켓은 데이터의 송수신에 사용된다형 서비스로 가상 회선 방식을 제공한다.

- 서버와 클라이언트는 1대1로 연결된다.

- 스트림 전송으로 전송 데이터의 크기가 무제한이다.

- 패킷에 대한 응답을 해야하기 때문에(시간 지연, CPU 소모) 성능이 낮다.

- Streaming 서비스에 불리하다.(손실된 경우 재전송 요청을 하므로)




# 📌 UDP
## ✅ UDP란?
- User Datagram Protocol
- 데이터를 데이터그램 단위로 처리하는 프로토콜
- 데이터그램이란 독립적인 관계를 지니는 패킷

## ✅ 동작 원리
TCP와 달리 UDP는 비연결형 프로토콜이다. 즉, 연결을 위해 할당되는 논리적인 경로가 없기 때문에 , 각각의 패킷은 다른 경로로 전송되고, 각각의 패킷은 독립적인 관계를 지니게 되는데 이렇게 데이터를 서로 다른 경로로 독립적으로 처리하는 프로토콜

![](https://images.velog.io/images/kcwthing1210/post/53d24897-6433-45cf-9c3b-bbb05083d282/image.png)



## ✅ UDP 특징
- 비연결형 서비스로 데이터그램 방식을 제공한다

- 정보를 주고 받을 때 정보를 보내거나 받는다는 신호절차를 거치지 않는다.

- UDP헤더의 CheckSum 필드를 통해 최소한의 오류만 검출한다.

- 신뢰성이 낮다

- TCP보다 속도가 빠르다



UDP는 비연결형 서비스이기 때문에, 연결을 설정하고 해제하는 과정이 존재하지 않습니다. 서로 다른 경로로 독립적으로

처리함에도 패킷에 순서를 부여하여 재조립을 하거나 흐름 제어 또는 혼잡 제어와 같은 기능도 처리하지 않기에 TCP보다

속도가 빠르며 네트워크 부하가 적다는 장점이 있지만 신뢰성있는 데이터의 전송을 보장하지는 못합니다. 그렇기 때문에

신뢰성보다는 연속성이 중요한 서비스 예를 들면 실시간 서비스(streaming)에 자주 사용됩니다.




## ✅ UDP 서버의 특징
- UDP에는 연결 자체가 없어서(connect 함수 불필요) 서버 소켓과 클라이언트 소켓의 구분이 없다.

- 소켓 대신 IP를 기반으로 데이터를 전송한다.

- 서버와 클라이언트는 1대1, 1대N, N대M 등으로 연결될 수 있다.

- 데이터그램(메세지) 단위로 전송되며 그 크기는 65535바이트로, 크기가 초과하면 잘라서 보낸다.

- 흐름제어(flow control)가 없어서 패킷이 제대로 전송되었는지, 오류가 없는지 확인할 수 없다.

- 파일 전송과 같은 신뢰성이 필요한 서비스보다 성능이 중요시 되는 경우에 사용된다.

# 📌 TCP와 UDP 비교
![](https://images.velog.io/images/kcwthing1210/post/f675cdfa-ea7b-4a70-9d74-5dd1ea445f46/image.png)

## ❗ Q&A
**Q) 패킷(Packet)이란?**



인터넷 내에서 데이터를 보내기 위한 경로배정(라우팅)을 효율적으로 하기 위해서 데이터를 여러 개의 조각들로 나누어 전송을 하는데 이때, 이 조각을 패킷이라고 합니다.





**Q) TCP는 패킷을 어떻게 추적 및 관리하나요?**



위에서 데이터는 패킷단위로 나누어 같은 목적지(IP계층)으로 전송된다고 설명하였습니다. 예를 들어 한줄로 서야하는 A,B,C라는 사람(패킷)들이 서울(발신지)에서 출발하여 부산(수신지)으로 간다고 합시다. 그런데 A,B,C가 순차적으로 가는 상황에서 B가 길을 잘못 들어서 분실되었다고 합시다. 하지만 목적지에서는 A,B,C가 모두 필요한지 모르고 A,C만 보고 다 왔다고 착각할 수 있습니다. 그렇기 때문에 A,,B,C라는 패킷에 1,2,3이라는 번호를 부여하여 패킷의 분실 확인과 같은 처리를 하여 목적지에서 재조립을 합니다. 이런 방식으로 TCP는 패킷을 추적하며, 나누어 보내진 데이터를 받고 조립을 할 수 있습니다.


**Q) 흐름제어(Flow Control)와 혼잡제어(Congestion Control)이란?**



흐름제어는 데이터를 송신하는 곳과 수신하는 곳의 데이터 처리 속도를 조절하여 수신자의 버퍼 오버플로우를 방지하는 것입니다. 예를 들어 송신하는 곳에서 감당이 안되게 데이터를 빠르게 많이 보내면 수신자에서 문제가 발생하기 때문입니다.

혼잡제어는 네트워크 내의 패킷 수가 넘치게 증가하지 않도록 방지하는 것입니다. 만약 정보의 소통량이 과다하면

패킷을 조금만 전송하여 혼잡 붕괴 현상이 일어나는 것을 막습니다.

# 🧩 Reference
- https://mangkyu.tistory.com/15 [MangKyu's Diary]

# 🎁 대칭키, 공개키
개인키 = 비밀키 = 비공개키

공개키 기법 = 비대칭키 기법



# 📌 대칭키
- 하나의 비밀키를 양쪽(client & server)가 모두 같이 사용

- 암호화와 복호화에 사용하는 키가 같은 암호화 알고리즘

- 공개키와 비밀키를 별도로 가지는 것과 구별되는데, 이와 비교하면 계산속도가 빠르다는 장점

- 비밀키 하나만 알아내면 암호화된 내용을 해독 가능 → 해커로부터 안전 X

- 대킹키 암호는 암호화하는 단위에 따라 스트림암호와 블록암호로 나눌 수 있음

  º 스트림암호는 연속적인 비트/바이트를 계속해서 입력받아, 그에 대응하는 암호화 비트/마이트를 생성하는 방식

º 블록암호는 정해진 한 단위(블록)을 입력받아 그에 대응하는 암호화 블록을 생성하는 방식

º 블록암호의 경우 적절한 운용모드를 조합하면 블록 단위보다 큰 입력을 처리할 수 있음. 또한 스트림암호와 유사하게 지속적인 입력에 대해 동작할 수 있음. (대신 입출력 단위는 스트림암호보다 큰 블록 단위가 됨)

- 대킹키 기법을 사용하는 암호 알고리즘 방식으로 DES, 3-DES, AES, SEED, ARIA, MASK 등이 있다.

# 📌 공개키
![](https://images.velog.io/images/kcwthing1210/post/6671161a-97e1-49d3-8258-d5b07b96fd0e/image.png)

- 비밀키 하나 만 가지는 대칭키 암호 방법과 달리, 공개키와 비밀키 두 개가 존재

- 공개키 암호를 구성하는 알고리즘을 대칭키 암호 방식과 비교하여 비대칭 암호라고 불림

- 암호화와 복호화에 사용하는 키가 서로 다름

- 암호화할 때의 키는 공개키(public key), 복호화할 때의 키는 개인키(private key)

- 공개키는 누구나 알 수 있지만, 그에 대응하는 비밀키는 키의 소유자만이 알 수 있어서

  특정한 비밀키를 가지는 사용자만이 내용을 열어볼 수 있도록 하는 방식.

- 공개키로 암호화한 메세지는 수신자의 개인키로만 해독할 수 있으므로 안전하게 상대방에게 메세지를 전달해 줄 수 있음.

- 대칭키(비밀키)알고리즘에 비하여 속도가 느리다. (약 1000배)

- 속도가 느리기 때문에 긴문서의 암호화하는 경우보다 대칭키 알고리즘의 키값에 대한 암호에 사용.

- 대표적인 공개키 알고리즘으로 RSA, Elgamal 등이 있음.

## ✅ 동작원리

송신자는 수신자의 공개키를 받아 데이터를 암호화하여

네트워크를 통해 원격지에 전달.

수신자는 공개키로 암호화된 데이터를 자신의 개인키로 데이터를 복호화하여 평문을 복원.

![](https://images.velog.io/images/kcwthing1210/post/0556212b-8e21-47f2-b7d7-4fb19eebc0e6/image.png)

# 📌 공개키 비밀키 비교

![](https://images.velog.io/images/kcwthing1210/post/b6efbfe9-f8fb-424c-87ab-7ac54fd91da5/image.png)
# 🧩 Reference
- https://velog.io/@gs0351/%EB%8C%80%EC%B9%AD%ED%82%A4-vs-%EA%B3%B5%EA%B0%9C%ED%82%A4%EB%B9%84%EB%8C%80%EC%B9%AD%ED%82%A4

- https://gaeko-security-hack.tistory.com/123

# 🎁 HTTP & HTTPS

# 📌 HTTP

## ✅ HTTP(Hyper Text Transfer Protocol)란?
- 서버/클라이언트 모델을 따라 데이터를 주고 받기 위한 프로토콜
- 즉, HTTP는 인터넷에서 하이퍼텍스트를 교환하기 위한 통신 규약으로, 80번 포트를 사용하고 있다. 따라서 HTTP 서버가 80번 포트에서 요청을 기다리고 있으며, 클라이언트는 80번 포트로 요청을 보내게 된다.
- HTTP는 1989년 팀 버너스 리(Tim Berners Lee)에 의해 처음 설계되었으며, WWW(World-Wide-Web) 기반에서 세계적인 정보를 공유하는데 큰 역할을 하였다.


## ✅ HTTP의 구조

HTTP는 애플리케이션 레벨의 프로토콜로 TCP/IP 위에서 작동한다. HTTP는 상태를 가지고 있지 않는 Stateless 프로토콜이며 Method, Path, Version, Headers, Body 등으로 구성된다.

![](https://images.velog.io/images/kcwthing1210/post/7aa3e217-bd3c-4f59-b8f7-f4b3c20d2d32/image.png)

하지만 HTTP는 암호화가 되지 않은 평문 데이터를 전송하는 프로토콜이였기 때문에, HTTP로 비밀번호나 주민등록번호 등을 주고 받으면 제3자가 정보를 조회할 수 있었다. 그리고 이러한 문제를 해결하기 위해 HTTPS가 등장하게 되었다.



# 📌 HTTPS

## ✅ HTTPS란?
- HyperText Transfer Protocol over Secure Socket Layer, HTTP over TLS, HTTP over SSL, HTTP Secure 등으로 불림
- HTTPS는 HTTP에 데이터 암호화가 추가된 프로토콜
- HTTPS는 HTTP와 다르게 443번 포트를 사용하며, 네트워크 상에서 중간에 제3자가 정보를 볼 수 없도록 암호화를 지원하고 있다.



## ✅ HTTPS의 동작 과정
HTTPS는 대칭키 암호화와 비대칭키 암호화를 모두 사용하여 빠른 연산 속도와 안정성을 모두 얻고 있다.

HTTPS 연결 과정(Hand-Shaking)에서는 먼저 서버와 클라이언트 간에 세션키를 교환한다. 여기서 세션키는 주고 받는 데이터를 암호화하기 위해 사용되는 대칭키이며, 데이터 간의 교환에는 빠른 연산 속도가 필요하므로 세션키는 대칭키로 만들어진다.
문제는 이 세션키를 클라이언트와 서버가 어떻게 교환할 것이냐 인데, 이 과정에서 비대칭키가 사용된다.

즉, 처음 연결을 성립하여 안전하게 세션키를 공유하는 과정에서 비대칭키가 사용되는 것이고, 이후에 데이터를 교환하는 과정에서 빠른 연산 속도를 위해 대칭키가 사용되는 것이다.

![](https://images.velog.io/images/kcwthing1210/post/5dc94d87-2504-49f1-bac9-d151acae6501/image.png)

1. 클라이언트(브라우저)가 서버로 최초 연결 시도를 함
2. 서버는 공개키(엄밀히는 인증서)를 브라우저에게 넘겨줌
3. 브라우저는 인증서의 유효성을 검사하고 세션키를 발급함
4. 브라우저는 세션키를 보관하며 추가로 서버의 공개키로 세션키를 암호화하여 서버로 전송함
5. 서버는 개인키로 암호화된 세션키를 복호화하여 세션키를 얻음
6. 클라이언트와 서버는 동일한 세션키를 공유하므로 데이터를 전달할 때 세션키로 암호화/복호화를 진행함


![](https://images.velog.io/images/kcwthing1210/post/49427030-061c-4aa0-953e-4991f29175f4/https%EC%9D%B4%EB%AF%B8%EC%A7%80.png)

## ✅ HTTPS의 발급과정
위의 과정에서 추가로 살펴봐야 할 부분은 서버가 대칭키를 발급받는 과정이다. 서버는 클라이언트와 세션키를 공유하기 위한 공개키를 생성해야 하는데, 일반적으로는 인증된 기관(Certificate Authority) 에 공개키를 전송하여 인증서를 발급받고 있다. 자세한 과정은 다음과 같다.

1. A기업은 HTTP 기반의 애플리케이션에 HTTPS를 적용하기 위해 공개키/개인키를 발급함
2. CA 기업에게 돈을 지불하고, 공개키를 저장하는 인증서의 발급을 요청함
3. CA 기업은 CA기업의 이름, 서버의 공개키, 서버의 정보 등을 기반으로 인증서를 생성하고, CA 기업의 개인키로 암호화하여 A기업에게 이를 제공함
4. A기업은 클라이언트에게 암호화된 인증서를 제공함
   브라우저는 CA기업의 공개키를 미리 다운받아 갖고 있어, 암호화된 인증서를 복호화함
5. 암호화된 인증서를 복호화하여 얻은 A기업의 공개키로 세션키를 공유함

![](https://images.velog.io/images/kcwthing1210/post/311d5d1a-0ad2-440c-a9cb-6b84fea77b39/image.png)

인증서는 CA의 개인키로 암호화되었기 때문에, 신뢰성을 확보할 수 있고, 클라이언트는 A 기업의 공개키로 데이터를 암호화하였기 때문에 A기업만 복호화하여 원본의 데이터를 얻을 수 있다. 여기서 인증서에는 A 기업의 공개키가 포함되어 있으므로, A 기업의 공개키라고 봐도 무방하다. 또한 브라우저에는 인증된 CA 기관의 정보들이 사전에 등록되어 있어 인증된 CA 기관의 인증서가 아닐 경우에는 다음과 같은 형태로 브라우저에서 보여지게 된다.
![](https://images.velog.io/images/kcwthing1210/post/b10b73ec-0ded-47bb-b128-6f58b88c5be0/image.png)

# 📌 HTTP와 HTTPS
![](https://images.velog.io/images/kcwthing1210/post/8bb83f3b-31ac-4075-8bc8-b8187356d8a7/image.png)

HTTP와 HTTPS의 가장 커다란 차이점은 바로 SSL 인증서이다. SSL 인증서는 사용자가 사이트에 제공하는 정보를 암호화한다. 이렇게 전송된 데이터는 중간에서 누군가 훔쳐 낸다고 하더라도 데이터가 암호화 되어 있기때문에 해독 할 수 없다. 그 외에도 HTTPS는 TLS(전송계층 보안) 프로토콜을 통해서도 보안을 유지한다. TSL은 데이터 무결성을 제공하기 때문에 데이터가 전송 중에 수정되거나 손상되는 것을 방지하고 사용자가 자신의 의도하는 웹사이트와 통신하고 있음을 입증하는 인증 기능도 제공하고 있다.


HTTP는 암호화가 추가되지 않았기 때문에 보안에 취약한 반면, HTTPS는 안전하게 데이터를 주고받을 수 있다. 하지만 HTTPS를 이용하면 암호화/복호화의 과정이 필요하기 때문에 HTTP보다 속도가 느리다. (물론 오늘날에는 거의 차이를 못느낄 정도이다.) 또한 HTTPS는 인증서를 발급하고 유지하기 위한 추가 비용이 발생하다.

그렇다면 언제 HTTP를 쓰고, 언제 HTTPS를 쓰는 것이 좋겠는가?

개인 정보와 같은 민감한 데이터를 주고 받아야 한다면 HTTPS를 이용해야 하지만, 노출이 되어도 괜찮은 단순한 정보 조회 등 만을 처리하고 있다면 HTTP를 이용하면 된다.


# 🧩 Reference
-  https://mangkyu.tistory.com/98 [MangKyu's Diary]
- https://brunch.co.kr/@hyoi0303/10


# 🎁 HTTP 1.1 vs HTTP 2.0 vs HTTP 3.0

# 📌 HTTP 1.1
## ✅ HTTP 1.1이 느린 이유
- 연결당 하나의 요청과 응답을 처리하기 때문에 동시 전송 문제와 다수의 - 리소스를 처리하기에 속도와 성능 이슈가 존재
    - HOL(Head Of Line) Blocking (특정 응답 지연)
- HTTP/1.1의 사양상의 제한으로 클라이언트의 리퀘스트의 순서와 서버의 응답순서는 동기화해야 됨
- RTT(Round Trip TIme) 증가 (양방향 지연)
    - 헤더가 크다 (특히 쿠키 때문)
    - http/1.1의 헤더에는 많은 메타 정보들이 저장되어 있음.
    - 사용자가 방문한 웹페이지는 다수의 http 요청이 발생하게 되는데 이 경우 매 요청시 마다 중복된 헤더 값을 전송하게 되며 각 도메인에 설정된 쿠키 정보도 매 요청시 마다 헤더에 포함되어 전송

# 📌 HTTP 2.0
![](https://images.velog.io/images/kcwthing1210/post/cbcbda98-ec32-4c00-a938-76f38801040e/image.png)

## ✅ HTTP/2.0의 등장
- SDPY(구글 제안 프로토콜) 기반으로 HTTP/2.0 등장
- HTTP/2.0은 HTTP/1.1이 느려서 버전을 개선한 것

## ✅ HTTP/2.0이 빠른 이유
- Multiplexed Streams (한 커넥션에 여러개의 메세지를 동시에 주고 받을 수 있음)
- 요청이 커넥션 상에서 다중화 되므로 HOL(Head Of Line) Blocking 이 발생하지 않음
- Stream Prioritization (요청 리소스간 의존관계를 설정)
- Header Compression (Header 정보를 HPACK 압축 방식을 이용하여 압축 전송)
- Server Push (HTML문서 상에 필요한 리소스를 클라이언트 요청없이 보내줄 수 있음)
- 프로토콜 협상 메커니즘 - 프로토콜 선택, 예. HTTP / 1.1, HTTP / 2 또는 기타.
- HTTP / 1.1과의 높은 수준의 호환성 - 메소드, 상태 코드, URI 및 헤더 필드
- 페이지 로딩 속도 향상

# 📌 HTTP 3.0

가장 큰 특징은 TCP가 아닌 UDP를 사용한다는 것이다.

정확히 말하면 HTTP3는 QUIC라는 프로토콜 위에서 돌아가는 HTTP인데, QUIC는 Quick UDP Internet Connection의 약자로 UDP를 사용하는 프로토콜이다.

![](https://images.velog.io/images/kcwthing1210/post/10666c1a-1f70-42f4-8b57-a900f1e75ba2/image.png)

TCP는 3 way hand shake, 끝날 때 4way hand shake 등 오버헤드와 HOLB 등의 문제를 피할 수 없다.

QUIC는 TCP hand shake 과정을 최적화하는 것에 초점을 맞추어 설계되었다.

UDP는 데이터그램 방식을 사용하는 프로토콜이기에 각각의 패킷 간 순서가 존재하지 않는 독립적인 패킷이다.

UDP는 TCP에 비해 헤더가 많이 비어있기에, 커스터마이징할 수 있는 여지가 많고 이를 이용해 개발자가 구현을 어떻게 하느냐에 따라서 신뢰성을 확보할 수 있다.

## ✅ QUIC

### ✔ 연결 레이턴시 감소
RTT : Round Trip Time. 클라이언트가 요청하고 서버가 처리해 다시 응답해주는 사이클

HTTPS over TCP + TLS 소요 레이턴시 : 1RTT(TCP) + 2RTT(TLS) = 3RTT

HTTPS over QUIC 소요 레이턴시 : 1RTT

첫번째 hand shake를 할 때 연결 설정에 필요한 정보와 데이터를 함께 보내 RTT를 것이다. TCP+TLS는 데이터 보내기 전 신뢰성 있는 연결과 암호화에 필요한 정보를 교환 후 데이터를 교환한다.

### ✔ 패킷 손실 감지에 걸리는 시간 단축
TCP는 송신 측이 패킷을 보낸 후 타이머를 사용해 일정 시간 동안 응답이 오지 않으면 패킷이 손상되었다고 판단해 재전송한다. 이때 문제는 TCP가 타임아웃을 언제 낼 것인가를 동적으로 계산해야 한다. 패킷 재전송시 ACK을 받았을 때 첫 번째로 보낸 패킷의 ACK인지 두 번째로 보낸 패킷의 ACK인지 확인해야 한다. 이를 재전송 모호성이라고 한다.

QUIC는 헤더에 별도의 패킷 번호 공간을 부여해 패킷 손실 감지에 걸리는 시간을 단축한다.

### ✔ 멀티플렉싱 지원
여러 개의 스트림을 사용하면 특정 스트림의 패킷이 손실되어도 해당 스트림에만 영향을 미치고 나머지 스트림은 멀쩡히 사용할 수 있다.

HTTP2와 마찬가지로 멀티플렉싱을 지원해 이점을 그대로 가져간다

### ✔ 클라이언트의 IP가 바뀌어도 연결 유지
TCP는 발신지 IP, 발신지 port, 수신지 IP, 수신지 port로 연결을 식별해 클라이언트 IP가 바뀌면 연결이 끊어져 버린다. 이는 다시 연결을 생성하기 위해 3 way hand shake를 다시 해야하고, 레이턴시가 또 다시 발생된다.

요즘같이 모바일로 인터넷을 사용하는 경우 wifi에서 셀룰러로 전환될 때 클라이언트 IP 전환되는 경우가 많아 문제가 심각해진다.

QUIC는 connection ID사용해 서버와 연결을 생성한다. 이는 클라이언트 IP와는 전혀 무관하기 때문에 클라이언트 IP가 변경되더라도 기존의 연결을 계속 유지할 수 있다.

# 🧩 Reference
- https://woojinger.tistory.com/85
- https://seokbeomkim.github.io/posts/http1-http2/
